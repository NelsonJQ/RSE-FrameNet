{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG application using open-source models\n",
    "Code adapted from https://github.com/svpino/llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!pip install pypdf\n",
    "!pip install langchain_community\n",
    "!pip install langchain[docarray]\n",
    "!pip  install pydantic==1.10.9\n",
    "!pip install langchain\n",
    "!pip install pandas\n",
    "!pip install chromadb\n",
    "!pip install -qU langchain-text-splitters\n",
    "!pip install rank_bm25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "#load_dotenv()\n",
    "\n",
    "#OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "#MODEL = \"gpt-3.5-turbo\"\n",
    "#MODEL = \"mixtral:8x7b\"\n",
    "MODEL = \"llama3:8b\"\n",
    "MODEL = \"llama3:8b-instruct-q4_0\"\n",
    "\n",
    "REPORTING_YEAR = \"2023\"\n",
    "COMPANY_NAME = \"Kering\"\n",
    "COMPANY_DESCRIPTION = \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the questions file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "#from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "#from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "if MODEL.startswith(\"gpt\"):\n",
    "    model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=MODEL)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "else:\n",
    "    model = Ollama(model=MODEL)\n",
    "    embeddings = OllamaEmbeddings(model=MODEL, show_progress=True, num_gpu=1)\n",
    "\n",
    "#model.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.invoke(\"Raconte-moi une blague\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = model | parser \n",
    "#chain.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nYou are an expert in ecology and environmental issues. Your job is to examinate environmental claims of Kering based on their financial and sustainability report for the year 2023. You will always reply in French. Answer the question based on the context below and following the given answer format. Always add to your answer actual quotes of the full sentences you used as a source. If you can\\'t answer the question, reply \"I don\\'t know\".\\n\\nContext: Here is some context\\n\\nQuestion: Here is a question\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are an expert in ecology and environmental issues. Your job is to examinate environmental claims of {COMPANY_NAME} based on their financial and sustainability report for the year {REPORTING_YEAR}. You will always reply in French. Answer the question based on the context below and following the given answer format. Always add to your answer actual quotes of the full sentences you used as a source. If you can't answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Here is some context\", question=\"Here is a question\", COMPANY_NAME=COMPANY_NAME, REPORTING_YEAR=REPORTING_YEAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot Frame elements extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 20 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   ID                  20 non-null     object\n",
      " 1   Question            20 non-null     object\n",
      " 2   RSEframe            20 non-null     object\n",
      " 3   FrameNet            20 non-null     object\n",
      " 4   Definition          20 non-null     object\n",
      " 5   CoreFE              20 non-null     object\n",
      " 6   NonCoreFE           20 non-null     object\n",
      " 7   MultiQuestion       20 non-null     bool  \n",
      " 8   QuestionsMultiples  10 non-null     object\n",
      " 9   AnswerTemplate      20 non-null     object\n",
      " 10  AnswExamples        20 non-null     object\n",
      " 11  Relevantinfo        8 non-null      object\n",
      " 12  UnknownExample      20 non-null     object\n",
      " 13  Example_1_Kering    3 non-null      object\n",
      " 14  Example_2_Kering    3 non-null      object\n",
      " 15  Example_3_Kering    3 non-null      object\n",
      " 16  Commentaires        3 non-null      object\n",
      " 17  Keywords            3 non-null      object\n",
      " 18  Reponse             20 non-null     object\n",
      " 19  RetrievedContext    20 non-null     object\n",
      "dtypes: bool(1), object(19)\n",
      "memory usage: 3.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# Lisez le fichier Excel avec les réponses\n",
    "df_frames = pd.read_excel(\"df_frames_sent.xlsx\")\n",
    "\n",
    "# Afficher le df.info\n",
    "df_frames.info()\n",
    "\n",
    "# Output folder to be used as input of answers from the RAG model\n",
    "output_folder = \"output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Ollama chain to extract the frame elements and trigger words from each sentence in df_frames\n",
    "def model_frames(sent, frame_description, frame_name, frame_elements):\n",
    "    \n",
    "\n",
    "    template_base_french = \"\"\"\"\n",
    "    Vous êtes un expert en linguistique, rôles sémantiques et sémantique de cadres (cadre sémantique = semantic frame, a kind of event). Un élément de cadre (Frame element) est un rôle sémantique, par example: Agent, Récipient, Instrument, Lieu, Cause. Votre travail comprend 3 tâches à faire sur la phrase \"{sentence}\": 1, extraire les \"\"\" + f\"\"\"éléments de l'action \"{frame_name}\" (description = \"{frame_description}\") qui sont présents dans la phrase seulement parmi les catégories d'éléments suivantes \"{frame_elements}\"; 2, indiquez la position de début (start_index = starting index in the Sentence string) et de fin (end_index = ending index in the Sentence string) de chaque élément comme si c'était une entité nommée spaCy (['Lieu', 21, 33]) ; 3, extrayez le mot déclencheur (a noun or non-auxiliary verb in the sentence but never a preposition nor a grammar word, it can be simple or compound and it triggers the action related to the Frame_name \"{frame_name}\") en fonction de la description du cadre sémantique. Vous répondrez toujours en français. Si aucun élément de cadre sémantique n'est présent dans la phrase, répondez \"Je ne sais pas\".\n",
    "    \"\"\"\n",
    "    template_fr = f\"{template_base_french}\\nFormat de réponse attendu: Task1_FrameElements = ['element_category':'cited element from sentence', 'element2_category':'second element']. Task2_Indexes = [[21,25], [35, 74]]. Task3_TriggerWord = 'cited trigger word'\"\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(template_fr)\n",
    "    prompt.format(frame_description=frame_description, sentence=sent)\n",
    "    print(prompt.format(frame_description=frame_description, sentence=sent))\n",
    "    \n",
    "    chain = (\n",
    "    {\n",
    "        \"frame_description\": itemgetter(\"frame_description\"),\n",
    "        \"sentence\": itemgetter(\"sentence\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "    result = chain.invoke({\"sentence\": sent, \"frame_description\": frame_description})\n",
    "    print(result)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply the model_frames function to each row in the dataframe df_frames\n",
    "def extract_frame_elements(df):\n",
    "    # Create a copy of the input dataframe\n",
    "    df_results = df.copy()\n",
    "    \n",
    "    # Open the file in append mode\n",
    "    with open('output/resultFrames.txt', 'a') as f:\n",
    "        # Iterate over each row in the dataframe\n",
    "        for index, row in df.iterrows():\n",
    "            # Call the model_frames function with the values in the row\n",
    "            result = model_frames(row['Sentence'], row['FrameDefinition'], row['Frame'], row['FrameElements'])\n",
    "            \n",
    "            # Write the index, Frame, and result to the file, separated by tabs\n",
    "            f.write(f\"{str(index)}\\t{row['Frame']}\\t{str(result)}\\n\")\n",
    "\n",
    "            # Store the result in the corresponding Reponse column\n",
    "            df_results.at[index, 'Reponse'] = str(result)\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "# Apply the extract_frame_elements function to the test_df\n",
    "df_results = extract_frame_elements(df_frames)\n",
    "df_results\n",
    "# Export df_results to exce with headers\n",
    "df_results.to_excel(\"df_frame_results.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
